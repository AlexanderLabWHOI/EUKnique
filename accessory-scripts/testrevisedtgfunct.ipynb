{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Directory                       File        Index\n",
      "0     S0007  PN3_TP3_AX1_HT1_071119_S7  AX_HT_PN_TP\n",
      "0     S0006            AX3_071119_2_S6        AB_AX\n",
      "0     S0001            AX3_071119_1_S1        AB_AX\n",
      "0     S0008          PN3_PN2_071119_S8           PN\n",
      "0     S0003          TP1_TP2_071119_S3           TP\n",
      "0     S0002          AX1_HT1_071119_S2        AX_HT\n",
      "0     S0004          AX2_HT2_071119_S4        AX_HT\n",
      "0     S0005          AX4_PN1_071119_S5        AX_PN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vortexfs1/home/akrinos/.conda/envs/akrinos_env/lib/python3.6/site-packages/ipykernel_launcher.py:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "import subprocess\n",
    "import requests\n",
    "from snakemake.exceptions import print_exception, WorkflowError\n",
    "\n",
    "relative_dir = \"/vortexfs1/omics/alexander/akrinos/euknique\" # \"..\" if we're running from the scripts or something \n",
    "with open(relative_dir + \"/config.yaml\", \"r\") as configfile:\n",
    "    config = yaml.load(configfile)\n",
    "    \n",
    "relative_dir = config[\"homedir\"]\n",
    "    \n",
    "INPUTDIR = config[\"inputdir\"]\n",
    "SUBDIRECTDIR = config[\"subdirectory\"]\n",
    "REFERENCEDIR = config[\"referencedir\"]\n",
    "DATADIR = config[\"datadir\"]\n",
    "\n",
    "samples_avail = pd.read_csv(\"../data/forNCBI_MMETSP.csv\")\n",
    "sample_names = list(samples_avail.SAMPLE_NAME)\n",
    "sample_names = [curr.split(\"C\")[0].split(\"_\")[0] for curr in sample_names]\n",
    "    \n",
    "##### CREATE SUBDIRECTORY TABLE #####\n",
    "\n",
    "# We want to get the location of all the files we're interested in using.\n",
    "sampledirs = os.listdir(INPUTDIR)\n",
    "\n",
    "subdirectory_table = pd.DataFrame({'Directory': [], \\\n",
    "                                   'File': [], \\\n",
    "                                   'Index': []})\n",
    "\n",
    "for s in sampledirs:\n",
    "    files = list(set([p.split(\"_R\")[0] for p in os.listdir(os.path.join(INPUTDIR, s))]))\n",
    "    indices = [p.split(\"_S\")[0] for p in files]\n",
    "    indices = [\"\".join(i for i in index if not i.isdigit()) for index in indices]\n",
    "    indices = [index.split(\"_\") for index in indices]\n",
    "    \n",
    "    # this is only if you have the S000X in the file name\n",
    "    indices = [[i for i in indices_short if i != 'S'] for indices_short in indices]   \n",
    "\n",
    "    # AX3 indicates that we have an infected form of amoebaphyra\n",
    "    if \"AX3\" in files[0].split(\"_\"):\n",
    "        indices[0].append(\"AB\") \n",
    "    indices = [\"_\".join(sorted(list(set([i for i in index if i])))) for index in indices]\n",
    "    thisset = pd.DataFrame({'Directory': [s] * len(files), \\\n",
    "                            'File': files, \\\n",
    "                            'Index': indices})\n",
    "    subdirectory_table = subdirectory_table.append(thisset)\n",
    "\n",
    "print(subdirectory_table)\n",
    "subdirectory_table.to_csv(path_or_buf = os.path.join(relative_dir,SUBDIRECTDIR), sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'homedir': '/vortexfs1/omics/alexander/akrinos/euknique', 'inputdir': '/vortexfs1/omics/alexander/data/single-cell/2019-08-singlecell/WH_Pilot', 'outputdir': '/vortexfs1/omics/alexander/data/single-cell/alevin-WHPilot-12182019_2', 'scratch': '/vortexfs1/scratch/akrinos/drop-seq', 'indexdir': 'data/indices/', 'datadir': 'data/', 'referencedir': '/vortexfs1/omics/alexander/data/mmetsp/', 'configlist': 'alex,thaps,pn,het,amoeb', 'smallnamelist': 'AX,TP,PN,HT,AB', 'makesalmon': 1, 'maketg': 1, 'usereverse': 0, 'alex': 'Alexandrium-fundyense_MMETSP0347,Alexandrium-fundyense_MMETSP0196', 'ehux': 'Emiliania-huxleyi-374', 'thaps': 'Thalassiosira-sp._MMETSP1071', 'pn': 'Pseudo-nitzschia-pungens_MMETSP1060', 'het': 'Heterocapsa-triquestra_MMETSP0448', 'amoeb': 'Amoebophrya_MMETSP0795', 'subdirectory': 'data/subdirectory_table.tsv', 'date': '071119'}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['MMETSP0347', 'MMETSP0196'], ['MMETSP1071'], ['MMETSP1060'], ['MMETSP0448'], ['MMETSP0795']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The org_list is the name of all the organisms we want to get references for\n",
    "# This list has other entries in the configfile corresponding to the \n",
    "# reference we wish to use for that organism \n",
    "org_list = config[\"configlist\"].split(\",\")\n",
    "# The short_names list is the two-letter codes of these organisms\n",
    "short_names = config[\"smallnamelist\"].split(\",\")\n",
    "\n",
    "# Now we'll build a list of repeated entries based on how many references\n",
    "# we're using for each organism and where they are\n",
    "list_orgs_short = []\n",
    "MMETSP_names = []\n",
    "list_orgs = []\n",
    "for curr_num in range(len(org_list)):\n",
    "    curr = org_list[curr_num]\n",
    "    MMname_list = config[curr].split(\",\")\n",
    "    MMname_curr = []\n",
    "    orgnames_curr = []\n",
    "    for mm in MMname_list:\n",
    "        MMname_curr.append(mm.split(\"_\")[1])\n",
    "        orgnames_curr.append(mm.split(\"_\")[0])\n",
    "        \n",
    "    list_orgs_short.append(short_names[curr_num])\n",
    "    MMETSP_names.append(MMname_curr) # we want to add a list of entries if we have multiple transcriptomes/species\n",
    "    list_orgs.append(orgnames_curr)\n",
    "print(MMETSP_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMETSP0347\n",
      "MMETSP0196\n",
      "/vortexfs1/omics/alexander/akrinos/euknique/data/AX_combined_nt.fasta\n",
      "MMETSP1071\n",
      "/vortexfs1/omics/alexander/akrinos/euknique/data/TP_combined_nt.fasta\n",
      "MMETSP1060\n",
      "/vortexfs1/omics/alexander/akrinos/euknique/data/PN_combined_nt.fasta\n",
      "MMETSP0448\n",
      "/vortexfs1/omics/alexander/akrinos/euknique/data/HT_combined_nt.fasta\n",
      "MMETSP0795\n",
      "/vortexfs1/omics/alexander/akrinos/euknique/data/AB_combined_nt.fasta\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make a directory for each species of interest and then save the FASTA files from Zenodo corresponding to each given species of interest\n",
    "files_written = []\n",
    "for gg in range(0,len(MMETSP_names)):\n",
    "    file_names = []\n",
    "    for f in MMETSP_names[gg]:\n",
    "        # if the current sample is not in the MMETSP list\n",
    "        print(f)\n",
    "        if f not in sample_names:\n",
    "            file_names.append(os.path.join(DATADIR,\"Acatassembly.fasta\"))\n",
    "        else:\n",
    "            file_names.append(os.path.join(REFERENCEDIR, f + \"_clean.fasta\"))\n",
    "        \n",
    "    species_dir_name = os.path.join(relative_dir, DATADIR) \n",
    "    for f in range(0, len(file_names)):\n",
    "        curr_file = file_names[f]\n",
    "        to_write = species_dir_name + list_orgs[gg][f].replace(\" \", \"\") + \"_\" + MMETSP_names[gg][f] + \"_nt.fasta\"\n",
    "        os.system(\"cp \" + curr_file + \" \" + to_write)\n",
    "\n",
    "    os.system(\"cat \" + \" \".join(file_names) + \" > \" + os.path.join(relative_dir, DATADIR, list_orgs_short[gg].replace(\" \", \"\") + \"_\" + \"combined\" + \"_nt.fasta\"))\n",
    "    to_write = os.path.join(relative_dir, DATADIR, list_orgs_short[gg].replace(\" \", \"\") + \"_\" + \"combined\" + \"_nt.fasta\")\n",
    "    print(to_write)\n",
    "    files_written.append(to_write) # need to extend if using list option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the combined files of transcriptomes we just wrote\n",
    "counter = 0\n",
    "for ff in range(0,len(files_written)):\n",
    "    f = files_written[ff]\n",
    "    g = MMETSP_names[ff]\n",
    "    short_name = list_orgs_short[ff]\n",
    "    \n",
    "    file_loc = \"../data/tgMap_\" + short_name + \".tsv\"#list_orgs[ff].replace(\" \", \"-\") + \"_\" + g + \".tsv\"\n",
    "    os.system(\"touch \" + file_loc)\n",
    "\n",
    "    with open(\"../data/tgMap.tsv\", 'wt') as tgMap_file:\n",
    "        transcript_to_gene = csv.writer(tgMap_file, delimiter='\\t')\n",
    "        command = str(\"cat \" + str(f) + \" | grep \\\">\\\" | cut -f2 -d \\\">\\\" | cut -f1 -d \\\" \\\" > transcript_names.txt\")\n",
    "        #else:\n",
    "        #    command = str(\"cat \" + str(f) + \" | grep \\\">\\\" | cut -f2 -d \\\">\\\" > transcript_names.txt\")\n",
    "        os.system(command)\n",
    "        transcripts = open(\"transcript_names.txt\", \"r\")\n",
    "        for transcript in transcripts:\n",
    "            #if g == \"combined\":\n",
    "            #    genes = [transcript.replace(\"\\n\",\"\"), list_orgs_short[ff] + \"-\" + transcript.split(\"TRINITY_\")[1].split(\"_\")[0]]\n",
    "            #else:\n",
    "            genes = [transcript.replace(\"\\n\",\"\"), list_orgs_short[ff] + \"-\" + \"DN\" + transcript.split(\"|\")[3].replace(\"\\n\", \"\")]\n",
    "            counter = counter + 1\n",
    "            transcript_to_gene.writerow(genes)\n",
    "    \n",
    "    os.system(\"mv \" + os.path.join(relative_dir,\"data/tgMap.tsv \") + file_loc)\n",
    "    tgMap_file.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
